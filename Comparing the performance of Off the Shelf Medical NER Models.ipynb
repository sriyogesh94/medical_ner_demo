{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a basic spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_data_to_spacy(dict_deid_surrogate_test_all_groundtruth_version2,\n",
    "                          deid_surrogate_test_all_groundtruth_version2):\n",
    "    \n",
    "    dict_labels, dict_text = dict_deid_surrogate_test_all_groundtruth_version2, deid_surrogate_test_all_groundtruth_version2\n",
    "    sapcy_training_data = []\n",
    "    for key in dict_labels:\n",
    "        tags = dict_labels[key]\n",
    "        list_of_tags = []\n",
    "        for tag in tags:    \n",
    "            pattern = re.search(tag[1], dict_text[key][0][1])\n",
    "            if pattern:\n",
    "                list_of_tags.append((pattern.span()[0], pattern.span()[1], tag[0]))\n",
    "        sapcy_training_data.append((dict_text[key][0][1], {'entities': list_of_tags}))\n",
    "        \n",
    "    return sapcy_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def xml_parse_deid_surrogate_test_all_groundtruth_version2(file):\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot() \n",
    "    return {child.attrib['ID']: [(i.attrib['TYPE'], i.text) for i in child[0]] for child in root}\n",
    "\n",
    "def xml_parse_deid_surrogate_test_all_version2(file):\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    return {child.attrib['ID']: [(i.tag, i.text) for i in child] for child in root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = xml_parse_deid_surrogate_test_all_groundtruth_version2(\"data/deid_surrogate_test_all_groundtruth_version2.xml\")\n",
    "dict_text = xml_parse_deid_surrogate_test_all_version2('data/deid_surrogate_test_all_version2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = convert_data_to_spacy(dict_labels, dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "def train_spacy(training_data, output_dir = './'):\n",
    "\n",
    "    TRAIN_DATA = training_data\n",
    "    nlp = spacy.load('en')  \n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "    \n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  \n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                    [text],  \n",
    "                    [annotations], \n",
    "                    drop=0.2, \n",
    "                    sgd=optimizer, \n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "            \n",
    "    nlp.to_disk(output_dir)\n",
    "            \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statring iteration 0\n",
      "{'ner': 30777.25510596777}\n",
      "Statring iteration 1\n",
      "{'ner': 29202.463073653787}\n",
      "Statring iteration 2\n",
      "{'ner': 29082.50368124411}\n",
      "Statring iteration 3\n",
      "{'ner': 29070.937848038582}\n",
      "Statring iteration 4\n",
      "{'ner': 28679.794244414363}\n",
      "Statring iteration 5\n"
     ]
    }
   ],
   "source": [
    "new_nlp = train_spacy(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a basic CRF ( RASA NLU ) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
